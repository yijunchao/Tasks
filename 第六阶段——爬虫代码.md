# 爬虫代码

```
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import requests

headers = {
      'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                    'Chrome/90.0.4430.93 Safari/537.36',
      'Cookie' : 'user_locale=zh-CN; oschina_new_user=false; remote_way=http; Hm_lvt_24f17767262929947cc3631f99bfd274='
               '1642069180; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%2217e52f33f89df0-031c95bcb772f8c-5e181552-'
               '970307-17e52f33f8acbe%22%2C%22first_id%22%3A%22%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type'
               '%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%'
               '96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%2C%22%24latest_referrer%22%3A%22%22%7D%2C%'
               '22%24device_id%22%3A%2217e52f33f89df0-031c95bcb772f8c-5e181552-970307-17e52f33f8acbe%22%7D; sensorsdata'
               '2015jssdkchannel=%7B%22prop%22%3A%7B%22_sa_channel_landing_url%22%3A%22%22%7D%7D; slide_id=9; gitee-sess'
               'ion-n=em9sWGN5N3FtMzNuY1lUQkNKa3J1VjNzd08yT01NekxQVThaNzdsZ2E4ZXA3ZW1jOU9Ka0hISmJQZ1lYY2g5T0diMGtzVllRQ'
               'kpudnlUSUppNjQzU2c9PS0tMEhCTnpGOTFPNVFuaTBtc3VWU1d6UT09--1caa19ea2c7876271626336401caf1b571426a85'
}

chrome_options = Options()# 实例化一个启动参数对象
chrome_options.add_argument('--headless')  # 增加无界面选项
browser = webdriver.Chrome(chrome_options=chrome_options)

url = 'http://212.129.245.115/geek#/'


browser.get(url)

res = browser.page_source
# print(r)

bs = BeautifulSoup(res,'lxml')
# print(bs.text)

#文字

text = bs.text
print(text)

textpath = r'D:\text.txt'  #文字存储路径

with open(textpath, 'wb') as f:
    text = bytes(text, encoding='utf-8')
    f.write(text)

    f.close()


#图片

img = bs.find_all('img')
x = 0

for i in img:
    x += 1
    # print(i)
    imgsrc = i.get('src')

    r = requests.get(imgsrc, headers=headers)
    if r.status_code == 200:
        imgpath = r'D:\{}.jpg'.format(x)  # 设置图片存储路径
        with open(imgpath, 'wb') as f:
            f.write(r.content)
            print('图片保存成功')

            f.close()
print("all over!!!")
```

